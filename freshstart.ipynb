{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import httpagentparser\n",
    "\n",
    "pd.set_option('display.width', 400)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing tools and removing useless logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df.replace(\"-\", \"\",inplace = True)\n",
    "    df = df[pd.to_numeric(df['cs-bytes'], errors='coerce').notnull()]\n",
    "    df = df[pd.to_numeric(df['sc-bytes'], errors='coerce').notnull()]\n",
    "    #df[\"cs(Referer)\"] = df[\"cs(Referer)\"].to_string()\n",
    "    return df\n",
    "\n",
    "def remove_rows(data):\n",
    "    data= data.loc[(data['x-exception-id']==\"\")]\n",
    "    data.loc[data['cs-host']==\"\",'empty']=1\n",
    "    data['empty']=data['empty'].fillna(0)\n",
    "    col_name_skip = ['referer-protocol','referer-domain',\"referer-path\",\"cs-host\"]\n",
    "\n",
    "    for col in data.columns:\n",
    "        if col in col_name_skip:\n",
    "            pass\n",
    "        elif col=='cs-uri-path':\n",
    "            data.loc[data[col]==\"/\",\"empty\"]+=1\n",
    "\n",
    "        else:\n",
    "            data.loc[data[col]==\"\",\"empty\"]+=1\n",
    "    data=data.loc[data['empty']<6]\n",
    "    data=data.drop(columns=['empty','x-exception-id'])\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strange_status(a):\n",
    "    #a['sc-status'] = a['sc-status'].astype(float)\n",
    "    a['sc-status'] = pd.to_numeric(a['sc-status'],errors='coerce')\n",
    "    a['strange_status'] = np.where(a['sc-status'] < 399, 0, 1)\n",
    "    return a\n",
    "\n",
    "def strange_port(data,tab_port,tab_method):\n",
    "    data['strange_port'] = np.where(data['cs-uri-port'].isin(tab_port), 0, 1)\n",
    "    data.loc[(data['cs-method'].isin(tab_method)) & (data['strange_port']==1),'strange_port' ] +=1\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url(data, column_toparse, scheme=True, domain=True, path=True, params=False, query=False, fragment=False):\n",
    "    if column_toparse not in data.columns:\n",
    "        print(\"Column name not found\")\n",
    "        return 0\n",
    "    else:\n",
    "        data['referer-protocol'], data['referer-domain'], data['referer-path'], data['referer-params'], data['referer-query'], data['referer-fragment'] = zip(*data[column_toparse].map(urlparse))\n",
    "        choices = [scheme, domain, path, params, query, fragment]\n",
    "        names = ['referer-protocol', 'referer-domain', 'referer-path', 'referer-params', 'referer-query','referer-fragment']\n",
    "        indexes = np.where(choices)[0]\n",
    "        keep = []\n",
    "        for k in indexes:\n",
    "            keep.append(names[k])\n",
    "            dropped = list(set(names) - set(keep))\n",
    "        data = data.drop(columns=dropped)\n",
    "    return data\n",
    "def find_same_referer(data):\n",
    "    data.loc[data['cs-host'] != data['referer-domain'], 'changed'] = 1\n",
    "    data['changed'] = data['changed'].fillna(0)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_url_size(df,poids):\n",
    "    sum_column = df[\"cs-host\"].apply(lambda x: len(str(x))) + df[\"cs-uri-path\"].apply(lambda x: len(str(x)))\n",
    "    df['url_size'] = sum_column\n",
    "    threshold1=df[\"url_size\"].quantile(0.9)\n",
    "    threshold2=df[\"url_size\"].quantile(0.99)\n",
    "    df[\"url_size\"] = df[\"url_size\"].apply(lambda x :max(0,min(poids,poids*((x-threshold1)/(threshold2-threshold1)))))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def is_big_cs_bytes(df, quantile = 0.9):\n",
    "    df[\"bigcs\"] = df[\"cs-bytes\"].apply(lambda x: int(x))\n",
    "    value = df[\"bigcs\"].quantile(quantile)\n",
    "    df[\"bigcs\"] = df[\"bigcs\"].apply(lambda x: x >= value)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def extension_superior_than(df, size, quantile, tab_extension):\n",
    "    value = df[\"cs-uri-extension-frequency\"].quantile(quantile)\n",
    "\n",
    "    df[\"extension_strange\"] = np.where(df[\"cs-uri-extension-frequency\"] > value, 0, 1)\n",
    "    df['len-extension']=df['cs-uri-extension'].apply(lambda x  : len(str(x)))\n",
    "    df.loc[df['len-extension']>size,\"extension_strange\"]=0.5\n",
    "    df.loc[df['cs-uri-extension'].isin(tab_extension),\"extension_strange\"]=1\n",
    "    df[\"extension_strange\"]= df['extension_strange']*2\n",
    "    return df\n",
    "\n",
    "def amount_people_by(df, columnname):\n",
    "    columnname_by = str(\"people-by\")+str(columnname)\n",
    "    df[columnname_by] =  df.groupby([columnname]).nunique()\n",
    "\n",
    "def add_amount_people_by(df, columnname,quantile=0.9):\n",
    "    columnname_by = str(\"people_by\")+str(columnname)\n",
    "    df2 = df.drop_duplicates(subset=[columnname,\"c-ip\"])\n",
    "    df_frequency = df2.groupby([columnname]).count()\n",
    "    most_frequent = df_frequency.index.tolist()\n",
    "    quantity = df_frequency.iloc[:,0].tolist()\n",
    "\n",
    "    frequent_host_dict = dict(zip(most_frequent, quantity))\n",
    "\n",
    "    df[columnname_by] = df[columnname].apply(lambda x: frequent_host_dict.get(x))\n",
    "    value = df[columnname_by].quantile(quantile)\n",
    "    df[columnname_by] = df[columnname_by].apply(lambda x: x >= value)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_frequency(df, columnname):\n",
    "    columnnamefreq = str(columnname)+str(\"-frequency\")\n",
    "    df_frequency = df.groupby([columnname]).count()\n",
    "    most_frequent = df_frequency.index.tolist()\n",
    "    quantity = df_frequency.iloc[:,0].tolist()\n",
    "    frequent_host_dict = dict(zip(most_frequent, quantity))\n",
    "\n",
    "    df[columnnamefreq] = df[columnname].apply(lambda x: frequent_host_dict.get(x))\n",
    "    #print(df.head())\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_useragent(data,poids):\n",
    "    data['more_info']=data['cs(User-Agent)'].apply(lambda x : httpagentparser.simple_detect(x))\n",
    "    data['fishy_os']=data['more_info'].apply(lambda x :x.__contains__('Unknown OS'))\n",
    "    data['fishy_browser']=data['more_info'].apply(lambda x :x.__contains__('Unknown Browser'))\n",
    "    data['fishy_os']=(data['fishy_os'].astype(int))*poids\n",
    "    data['fishy_browser']=(data['fishy_browser'].astype(int))*poids\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VRUma\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (10,16,22,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "headerString = 'date time time-taken c-ip cs-username cs-auth-group x-exception-id sc-filter-result cs-categories cs(Referer) sc-status s-action cs-method rs(Content-Type) cs-uri-scheme cs-host cs-uri-port cs-uri-path cs-uri-query cs-uri-extension cs(User-Agent) s-ip sc-bytes cs-bytes x-virus-id'\n",
    "header = headerString.split(\" \")\n",
    "data = pd.read_csv('./Data/message.txt', delimiter=\"\\s+\", index_col=False, encoding=\"utf-8\", comment= \"#\", names=header)\n",
    "\n",
    "data=data.drop(columns=['cs-username','cs-auth-group','x-virus-id','time-taken','date','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_port = [80,443,\"80\",\"443\"]\n",
    "tab_method = [\"GET\",\"POST\",\"HEAD\",\"OPTIONS\",\"PUT\",\"CONNECT\"]\n",
    "\n",
    "\n",
    "data = preprocessing(data)\n",
    "data=remove_rows(data)\n",
    "\n",
    "data=parse_url(data,'cs(Referer)')\n",
    "data=strange_port(data,tab_port,tab_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = find_same_referer(data)\n",
    "data = is_big_cs_bytes(data)\n",
    "data = is_big_cs_bytes(data)\n",
    "data = strange_status(data)\n",
    "data=compute_url_size(data,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_amount_people_by(data,\"cs-host\")\n",
    "data = add_frequency(data, \"cs-uri-extension\")\n",
    "tab_extension = [\"dll\",\"zip\",\"rar\",\"bin\",\"exe\"]\n",
    "data = extension_superior_than(data, 20,0.004,tab_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=compute_useragent(data,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GETTING SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "score_cols = ['url_size', 'bigcs', 'strange_status',  'strange_port', 'people_bycs-host', 'changed','extension_strange','fishy_os','fishy_browser']\n",
    "data[\"sum\"] = data[score_cols].sum(axis=1)\n",
    "data = data.sort_values(by=[\"sum\"],ascending=False)\n",
    "data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### OLD PART ####\n",
    "def make_dummies(df, string):\n",
    "    df = pd.concat([df, pd.get_dummies(df[string], prefix=string)], axis=1)\n",
    "    df.drop([string], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def compute_similarity(string1, stand_val):\n",
    "    indexes = np.where(string1 == stand_val)\n",
    "    return indexes[0]\n",
    "\n",
    "def apply_sim(data, column_name, one_line_df, new_col_name):\n",
    "    if column_name not in data.columns:\n",
    "        print(\"Wrong column name\")\n",
    "        return 0\n",
    "    else:\n",
    "        list_indexes = compute_similarity(data[column_name].values, one_line_df[column_name].values[0])\n",
    "        data[new_col_name] = data.index.isin(list_indexes)\n",
    "        data[new_col_name] = data[new_col_name].astype(int)\n",
    "        return data\n",
    "\n",
    "def compute_all_sims(data, y):\n",
    "    all_cols = ['x-exception-id', 'cs-categories',\n",
    "              'sc-status', 's-action', 'cs-uri-scheme', 'cs-uri-port']\n",
    "    for col in all_cols:\n",
    "        apply_sim(data, col, y, 'sim')\n",
    "        if 'final_sim' not in data.columns:\n",
    "            data['final_sim'] = data['sim']\n",
    "        else:\n",
    "            data['final_sim'] = data['final_sim'] + data['sim']\n",
    "\n",
    "\n",
    "### adding the columns ###\n",
    "'''\n",
    "y=a.tail(1)\n",
    "a=make_dummies(a,'sc-filter-result')\n",
    "a = add_url_size(a)\n",
    "a = add_frequency(a,'cs-host')\n",
    "compute_all_sims(a,y)\n",
    "'''\n",
    "\n",
    "def normalization_zero_one(df, list_column):\n",
    "    for column in list_column:\n",
    "        df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "    return df\n",
    "\n",
    "def normalization_gauss(df, list_column):\n",
    "    for column in list_column:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
